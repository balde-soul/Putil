{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import torch\n",
    "import Putil.base.logger as plog\n",
    "from torch.nn.parallel import DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_logger = plog.PutilLogConfig('base_model').logger()\n",
    "base_model_logger.setLevel(plog.DEBUG)\n",
    "BaseModelLogger = base_model_logger.getChild('BaseModel')\n",
    "BaseModelLogger.setLevel(plog.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, opt, **kwargs):\n",
    "        self._schedulers = list()\n",
    "        self._opetimizers = list()\n",
    "        \n",
    "        # the path param\n",
    "        self._path = opt['path']\n",
    "        # the result param\n",
    "        assert 'result_save_path' in self._path, BaseModelLogger.fatal('result_save_path should be in opt['path'] vs. {0}'.format(self._path))\n",
    "        # the pre model param\n",
    "        assert 'pre_trained_model_path' in self._path\n",
    "        assert 'pre_epoch' in \n",
    "        assert 'pre_step' in \n",
    "        pass\n",
    "    \n",
    "    def save_network(self, network, epoch, step):\n",
    "        BaseModelLogger.info()\n",
    "        if isinstance(network, nn.DataParallel) or isinstance(network, DistributedDataParallel):\n",
    "            network = network.module\n",
    "            pass\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "            pass\n",
    "        save_file_name = '{0}-{1}.pth'.format(step, epoch)\n",
    "        save_file_path = os.path.join(self._path['result_save_path'], save_file_name)\n",
    "        torch.save(state_dict, save_file_path)\n",
    "        pass\n",
    "    \n",
    "    def save_training_state(self, epoch, step):\n",
    "        ''''''\n",
    "        state = {'epoch': epoch, 'step': step, 'schedulers': lsit(), 'optimizers': list()}\n",
    "        for s in self._schedulers:\n",
    "            state['schedulers'].append(s.state_dict())\n",
    "            pass\n",
    "        for o in self._optimizers:\n",
    "            state['optimizers'].append(o.state_dict())\n",
    "            pass\n",
    "        save_file_name = '{0}-{1}.state'.format(step, epoch)\n",
    "        save_file_path = os.path.join(self._path['result_save_path'], save_file_name)\n",
    "        torch.save(state, save_file_path)\n",
    "        pass\n",
    "    \n",
    "    def load_network(self):\n",
    "        if isinstance(network, nn.DataParallel) or isinstance(network, DistributedDataParallel):\n",
    "            network = network.module\n",
    "            pass\n",
    "        load_net = torch.load(self._load_path)\n",
    "        pass\n",
    "    \n",
    "    def _param_name_reflect_func(self, now_name):\n",
    "        return now_name\n",
    "        pass\n",
    "    \n",
    "    def get_save_training_state_file_name(self):\n",
    "        pass\n",
    "    \n",
    "    def save_network_with_training_state(self):\n",
    "        pass\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
